{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/geremiapompei/Desktop/Progetti/energiai\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "\n",
    "# !git clone https://github.com/GeremiaPompei/energiai\n",
    "# %cd energiai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from src.utility.hyperparams_generator import gridsearch_generator\n",
    "from src.runner.model_selection_pipeline import model_selection_pipeline\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gridsearch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "hyperparams_list = gridsearch_generator(\n",
    "    dict(\n",
    "        trainer_lr=[0.001, 0.1],\n",
    "        model_hidden_dim=[400],\n",
    "        model_latent_dim=[200],\n",
    "    )\n",
    ")\n",
    "model_selection_pipeline(hyperparams_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Randomsearch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-31 10:24:11,699 - root - INFO - Start iteration 1/100 => hyperparams: {'trainer_lr': 0.0026106005498359943, 'model_hidden_dim': 340, 'model_latent_dim': 310}\n",
      "2023-10-31 10:24:23,949 - root - INFO - Epoch 1/20 => training loss: 1039080.4879624664, test loss: 0.025316547312058894\n",
      "2023-10-31 10:24:35,382 - root - INFO - Epoch 2/20 => training loss: 8229.908339659522, test loss: 0.006489044800464311\n",
      "2023-10-31 10:24:46,800 - root - INFO - Epoch 3/20 => training loss: 3900.1197330780888, test loss: 0.007803047281218021\n",
      "2023-10-31 10:24:58,261 - root - INFO - Epoch 4/20 => training loss: 2684.600362714709, test loss: 0.004235247506763911\n",
      "2023-10-31 10:25:09,690 - root - INFO - Epoch 5/20 => training loss: 2190.984435741814, test loss: 0.002483408775641613\n",
      "2023-10-31 10:25:21,397 - root - INFO - Epoch 6/20 => training loss: 1974.621772854446, test loss: 0.0011408035369070528\n",
      "2023-10-31 10:25:33,113 - root - INFO - Epoch 7/20 => training loss: 1869.9641683848909, test loss: 0.000801777702281651\n",
      "2023-10-31 10:25:45,069 - root - INFO - Epoch 8/20 => training loss: 1824.937079087902, test loss: 0.00036240558004054657\n",
      "2023-10-31 10:25:56,677 - root - INFO - Epoch 9/20 => training loss: 1803.718786224447, test loss: 0.0002017402051621072\n",
      "2023-10-31 10:26:08,475 - root - INFO - Epoch 10/20 => training loss: 1794.0764504759372, test loss: 0.00011190952082068553\n",
      "2023-10-31 10:26:20,151 - root - INFO - Epoch 11/20 => training loss: 1789.241710778161, test loss: 6.724363830630707e-05\n",
      "2023-10-31 10:26:31,777 - root - INFO - Epoch 12/20 => training loss: 1786.7246618062736, test loss: 4.912921154176619e-05\n",
      "2023-10-31 10:26:43,447 - root - INFO - Epoch 13/20 => training loss: 1785.3361396368803, test loss: 4.028149599824423e-05\n",
      "2023-10-31 10:26:55,222 - root - INFO - Epoch 14/20 => training loss: 1784.4527789133822, test loss: 3.7975568443860005e-05\n",
      "2023-10-31 10:27:06,920 - root - INFO - Epoch 15/20 => training loss: 1783.8051582654807, test loss: 3.6391788204679054e-05\n",
      "2023-10-31 10:27:18,532 - root - INFO - Epoch 16/20 => training loss: 1783.2308548232133, test loss: 3.5489002247854685e-05\n",
      "2023-10-31 10:27:29,978 - root - INFO - Epoch 17/20 => training loss: 1782.7040864555456, test loss: 3.508459355132474e-05\n",
      "2023-10-31 10:27:41,586 - root - INFO - Epoch 18/20 => training loss: 1782.1932616696981, test loss: 3.492534707742373e-05\n",
      "2023-10-31 10:27:52,986 - root - INFO - Epoch 19/20 => training loss: 1781.722059655166, test loss: 3.489496659462318e-05\n",
      "2023-10-31 10:28:05,011 - root - INFO - Epoch 20/20 => training loss: 1781.3364803520763, test loss: 3.4768099037930156e-05\n",
      "2023-10-31 10:28:05,033 - root - INFO - Best loss: 3.4768099037930156e-05, best hyperparams: {'trainer_lr': 0.0026106005498359943, 'model_hidden_dim': 340, 'model_latent_dim': 310}\n",
      "2023-10-31 10:28:05,033 - root - INFO - Start iteration 2/100 => hyperparams: {'trainer_lr': 0.0034048469307695717, 'model_hidden_dim': 148, 'model_latent_dim': 258}\n",
      "2023-10-31 10:28:09,095 - root - INFO - Epoch 1/20 => training loss: 4.3606286530388465e+61, test loss: 0.10936683195205134\n",
      "2023-10-31 10:28:13,102 - root - INFO - Epoch 2/20 => training loss: 231238.82988445577, test loss: 0.05252572856625812\n",
      "2023-10-31 10:28:17,047 - root - INFO - Epoch 3/20 => training loss: 172656.05768797363, test loss: 0.03589205786096452\n",
      "2023-10-31 10:28:20,940 - root - INFO - Epoch 4/20 => training loss: 147931.14278591968, test loss: 0.03829000204069083\n",
      "2023-10-31 10:28:24,862 - root - INFO - Epoch 5/20 => training loss: 139104.1881012927, test loss: 0.03032836811747524\n",
      "2023-10-31 10:28:28,754 - root - INFO - Epoch 6/20 => training loss: 138085.42839565355, test loss: 0.029132102284402803\n",
      "2023-10-31 10:28:32,643 - root - INFO - Epoch 7/20 => training loss: 133848.99595728994, test loss: 0.028679075725272778\n",
      "2023-10-31 10:28:36,658 - root - INFO - Epoch 8/20 => training loss: 126067.79853756053, test loss: 0.025582059733601496\n",
      "2023-10-31 10:28:40,686 - root - INFO - Epoch 9/20 => training loss: 119357.69197222943, test loss: 0.023803148302378216\n",
      "2023-10-31 10:28:44,720 - root - INFO - Epoch 10/20 => training loss: 118204.0037171402, test loss: 0.019285958505903346\n",
      "2023-10-31 10:28:48,637 - root - INFO - Epoch 11/20 => training loss: 2702829.4650500626, test loss: 0.023332763168056388\n",
      "2023-10-31 10:28:52,528 - root - INFO - Epoch 12/20 => training loss: 4972411.637155803, test loss: 0.022473590096941744\n",
      "2023-10-31 10:28:56,514 - root - INFO - Epoch 13/20 => training loss: 116572.01701258373, test loss: 0.021800670301458214\n",
      "2023-10-31 10:29:00,426 - root - INFO - Epoch 14/20 => training loss: 115523.76267281557, test loss: 0.023177952542636385\n",
      "2023-10-31 10:29:04,406 - root - INFO - Epoch 15/20 => training loss: 113341.08570189588, test loss: 0.021962349145670648\n",
      "2023-10-31 10:29:08,442 - root - INFO - Epoch 16/20 => training loss: 114128.24231279615, test loss: 0.02288698213373885\n",
      "2023-10-31 10:29:12,390 - root - INFO - Epoch 17/20 => training loss: 115553.02167389586, test loss: 0.022206239910593617\n",
      "2023-10-31 10:29:16,482 - root - INFO - Epoch 18/20 => training loss: 111937.34021295208, test loss: 0.02167584004985436\n"
     ]
    }
   ],
   "source": [
    "hyperparams_list = [\n",
    "    dict(\n",
    "        trainer_lr=random.uniform(0, 0.01),\n",
    "        model_hidden_dim=random.randint(100, 400),\n",
    "        model_latent_dim=random.randint(100, 400),\n",
    "    ) for _ in range(100)\n",
    "]\n",
    "model_selection_pipeline(hyperparams_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
